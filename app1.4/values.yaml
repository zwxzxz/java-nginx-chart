# 是否前端应用(是输入true)
isFrontend: false
# 应用名(必填!!!)
name: 
# 强行指定命名空间
nameSpace: 
# 镜像信息
image:
  # 仓库
  registry: 
  # 镜像组(必填!!!)
  repository: 
  # 标签(必填!!!)
  tag: latest
  # 拉取策略：值：IfNotPresent/Always/Never
  pullPolicy: Always
  # 镜像拉取Secret
  pullSecret: 

# 容器声明端口(默认：前端:80,后端:8080)
containerPort: 

# 扩展容器声明端口
extraContainerPort:
  # - name: https
  #   containerPort: 443

# 创建service(关注应用是否有需求,一般只需gateway和前端需要)
createService: 

# 副本数
replicaCount: 1

# 挂载
mount:
  # 容器内挂载地址(不挂载设置[]或者为空)
  volumeMounts: 
    # - name: volume-platforms-statics
    #   mountPath: /data
  # 卷
  volumes: 
    # - name: volume-platforms-statics
    #   nfs:
    #     path: /data/nfs_k8s/platforms/dataPlatform
    #     server: k8s-master

# 环境变量
env:
  - name: TZ
    value: Asia/Shanghai
    
# jvm参数(只有后端可用)
JAVA_OPTS: -XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0 -Dfile.encoding=UTF-8 

# pod注解
podAnnotations:
  # test/xxx: 'true'

# service
service:
  # 服务类型可选: ClusterIP/NodePort/LoadBalancer
  type: ClusterIP
  ports:
    name: http
    # 不填写使用containerPort
    port: 
    # 不填写使用containerPort
    targetPort: http
    # type为NodePort时,不填写则随机生成nodePort
    nodePort: 

  # 扩展其他端口
  extraPorts: 
  # - name: xxx
  #   port: 7613
  #   targetPort: 7613
  #   nodePort: 31112

  # 会话保持: None/ClientIP
  sessionAffinity: 
  # 超时时间, sessionAffinity设置为ClientIP才有效
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
  # 外部流量策略: Cluster/Local
  externalTrafficPolicy:
  # 限制可以访问负载均衡器的源IP地址段
  loadBalancerSourceRanges: 
    # - 10.10.10.0/24
    # - 192.0.2.0/24
  # type为LoadBalancer时才需要填写负载均衡Ip
  loadBalancerIP: 


# 资源
resources:
  # 请求资源(不使用设置{}或者为空)
  requests: 
    cpu: 30m
    # memory: 256Mi
  # 限制资源
  limits: 
    # cpu: 200m
    memory: 1Gi

# 主机别名
hostAliases:
  # - ip: 172.16.21.182
  #   hostnames:
  #     - platforms.genericszz.cn
  #     - simulation-private-v2.genericszz.cn

# 探针
probe:
  backend:
    # 后端总开关(关了所有不可用)
    enabled: true

    # 容器启动检查探针
    startupProbe:
      enabled: true
      #150秒启动时间
      httpGet:
        path: /actuator/health
        port: http
      failureThreshold: 30
      periodSeconds: 4

    # 容器存活检查探针
    livenessProbe:
      enabled: true
      #1分钟4次,3次失败重启
      httpGet:
        path: /actuator/health
        port: http
      timeoutSeconds: 3
      periodSeconds: 15
  
    # 容器就绪检查探针,3次失败Service停止分发
    readinessProbe:
      enabled: false
      #1分钟4次
      httpGet:
        path: /actuator/health
        port: http
      timeoutSeconds: 3
      periodSeconds: 15

  frontend:
    # 前端总开关(关了所有不可用)
    enabled: true

    # 容器启动检查探针
    startupProbe:
      enabled: true
      #15秒启动时间
      httpGet:
        path: /nginx_status
        port: http
      failureThreshold: 5
      periodSeconds: 2

    # 容器存活检查探针
    livenessProbe:
      enabled: true
      #1分钟4次,3次失败重启
      httpGet:
        path: /nginx_status
        port: http
      timeoutSeconds: 3
      periodSeconds: 15
  
    # 容器就绪检查探针,3次失败Service停止分发
    readinessProbe:
      enabled: false
      #1分钟4次
      httpGet:
        path: /nginx_status
        port: http
      timeoutSeconds: 3
      periodSeconds: 15
  

  # 自定义容器启动检查探针
  customStartupProbe:
    # tcpSocket:
    #   port: http
    # #失败次数
    # failureThreshold: 3
    # #首次检查延迟时间
    # initialDelaySeconds: 30
    # #多久探测一次
    # periodSeconds: 10
    # #检查失败后重新认定检查成功的检查次数
    # successThreshold: 1
    # #探测超时时间
    # timeoutSeconds: 1

  # 自定义容器存活检查探针
  customLivenessProbe:
    # exec:
    #   command:
    #     - sh
    #     - '-c'
    #     - |
    #       if grep -q "ERROR" /logs/vbooster/error.*.log; then
    #         exit 1
    #       else
    #         exit 0
    #       fi
    # failureThreshold: 3
    # initialDelaySeconds: 30
    # periodSeconds: 10
    # successThreshold: 1
    # timeoutSeconds: 1

  # 自定义容器就绪检查探针
  customReadinessProbe:
    # httpGet:
    #   path: /actuator/prometheus
    #   port: http
    #   scheme: HTTP
    # failureThreshold: 3
    # periodSeconds: 10
    # successThreshold: 1
    # timeoutSeconds: 1


# 监控(只有后端有用)
metrics:
  # 是否启用 Prometheus 监控指标
  enabled: true
  # 指标路径
  path: /actuator/prometheus

# 自动扩缩容
autoscaling:
  # 开关
  enabled: false
  # 最小副本数
  minReplicas: 1
  # 最大副本数
  maxReplicas: 3
  # 内存指标值
  targetMemory: 75

# 链路追踪
skyWalking:
  # 开关
  enabled: false
  # skyWalking-OAP地址
  oapAdd: 
  # agent.jar地址
  jarPath: /skywalking/skywalking-agent/skywalking-agent.jar

# 容忍
tolerations:
  # - effect: NoSchedule
  #   key: node-role.kubernetes.io/master
  #   operator: Exists

# 亲和
affinity:
  # 节点亲和
  # nodeAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     nodeSelectorTerms:
  #       - matchExpressions:
  #           - key: node-role.kubernetes.io/control-plane
  #             operator: In
  #             values:
  #               - aa
  # pod间亲和
  # podAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     - labelSelector:
  #         matchLabels:
  #           app: vbooster-gateway
  #       topologyKey: kubernetes.io/hostname
  # pod间反亲和
  # podAntiAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     - labelSelector:
  #         matchLabels:
  #           app: vbooster-gateway
  #       topologyKey: kubernetes.io/hostname

# 节点标签选择部署节点
nodeSelector:
  # kubernetes.io/os: linux
  # node-role.kubernetes.io/control-plane: ''

# 节点名称选择部署节点(设置了请关闭 节点亲和 和 节点标签选择部署节点)
nodeName: 

# 重启策略
restartPolicy: Always

# 使用主机网络
hostNetwork: false

# DNS策略(主机网络使用ClusterFirstWithHostNet)
dnsPolicy: ClusterFirst

# dns配置
dnsConfig:
  # nameservers:
  #   - 114.114.114.114
  # searches:
  #   - ns1.svc.cluster-domain.example
  #   - my.dns.search.suffix
  # options:
  #   - name: edns0

# 历史版本数量
revisionHistoryLimit: 10

# 更新策略
strategy:
  # type: Recreate